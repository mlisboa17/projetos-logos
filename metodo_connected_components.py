#!/usr/bin/env python3
"""
M√âTODO CL√ÅSSICO: CONNECTED COMPONENTS LABELING
Baseado na pesquisa do usu√°rio - ideal para fundo removido
"""

import cv2
import numpy as np
import os
from datetime import datetime

def metodo_connected_components(img, pasta_resultado):
    """
    M√âTODO CL√ÅSSICO: Connected Components Labeling
    1. Remove fundo (limiariza√ß√£o)
    2. Encontra componentes conectados 
    3. Conta produtos automaticamente
    """
    print("\nüî¨ M√âTODO CONNECTED COMPONENTS")
    print("   üìñ Baseado na pesquisa: Connected Component Labeling")
    
    # ===== PASSO 1: CONVERS√ÉO PARA ESCALA DE CINZA =====
    print("   1Ô∏è‚É£ Convertendo para escala de cinza...")
    if len(img.shape) == 3:
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    else:
        gray = img.copy()
    
    cv2.imwrite(os.path.join(pasta_resultado, "01_grayscale.jpg"), gray)
    
    # ===== PASSO 2: REMO√á√ÉO DO FUNDO (LIMIARIZA√á√ÉO) =====
    print("   2Ô∏è‚É£ Removendo fundo com limiariza√ß√£o...")
    
    # Testar diferentes valores de threshold
    thresholds = [200, 180, 160, 140, 120]
    melhor_thresh = None
    melhor_count = 0
    
    for thresh_val in thresholds:
        # Limiariza√ß√£o INVERSA (produto = branco, fundo = preto)
        _, thresh = cv2.threshold(gray, thresh_val, 255, cv2.THRESH_BINARY_INV)
        
        # Limpeza morfol√≥gica para remover ru√≠do
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
        thresh_clean = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)
        thresh_clean = cv2.morphologyEx(thresh_clean, cv2.MORPH_CLOSE, kernel)
        
        # Contar componentes preliminar
        num_labels, _ = cv2.connectedComponents(thresh_clean)
        count = num_labels - 1  # -1 para ignorar fundo
        
        print(f"      Threshold {thresh_val}: {count} objetos")
        
        # Salvar para an√°lise
        cv2.imwrite(os.path.join(pasta_resultado, f"thresh_{thresh_val}.jpg"), thresh_clean)
        
        # Escolher threshold que detecta ~4 objetos (pr√≥ximo ao esperado)
        if abs(count - 4) < abs(melhor_count - 4) or melhor_thresh is None:
            melhor_count = count
            melhor_thresh = thresh_clean
    
    print(f"   ‚úì Melhor resultado: {melhor_count} objetos")
    
    # Se n√£o encontrou nenhuma imagem v√°lida, usar a primeira
    if melhor_thresh is None:
        print("   ‚ö†Ô∏è Usando threshold padr√£o (200)")
        _, melhor_thresh = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY_INV)
    
    cv2.imwrite(os.path.join(pasta_resultado, "02_binary_mask.jpg"), melhor_thresh)
    
    # ===== PASSO 3: CONNECTED COMPONENT LABELING =====
    print("   3Ô∏è‚É£ Aplicando Connected Component Labeling...")
    
    num_labels, labels = cv2.connectedComponents(melhor_thresh)
    total_produtos = num_labels - 1  # -1 para ignorar o fundo (label 0)
    
    print(f"      üîç Componentes detectados: {num_labels}")
    print(f"      üì¶ Produtos encontrados: {total_produtos}")
    
    # ===== PASSO 4: AN√ÅLISE DE CADA COMPONENTE =====
    print("   4Ô∏è‚É£ Analisando cada produto...")
    
    # Criar imagem colorida para visualizar componentes
    img_components = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)
    img_boxes = img.copy()
    
    produtos = []
    cores = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0), 
             (255, 0, 255), (0, 255, 255), (128, 128, 128)]
    
    for label in range(1, num_labels):  # Ignorar label 0 (fundo)
        # M√°scara para este componente
        component_mask = (labels == label).astype(np.uint8) * 255
        
        # Calcular √°rea
        area = np.sum(labels == label)
        
        # Filtrar componentes muito pequenos (ru√≠do)
        if area < 5000:
            print(f"      ‚ùå Componente {label}: {area} pixels (muito pequeno)")
            continue
        
        # Encontrar bounding box
        contours, _ = cv2.findContours(component_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        if len(contours) > 0:
            # Pegar maior contorno (caso tenha fragmentos)
            main_contour = max(contours, key=cv2.contourArea)
            x, y, w, h = cv2.boundingRect(main_contour)
            
            # Calcular caracter√≠sticas
            aspect_ratio = w / float(h)
            extent = cv2.contourArea(main_contour) / (w * h)
            
            produto = {
                'id': label,
                'area': area,
                'bbox': (x, y, w, h),
                'aspect_ratio': aspect_ratio,
                'extent': extent,
                'centro': (x + w//2, y + h//2)
            }
            produtos.append(produto)
            
            # Colorir componente
            cor = cores[label % len(cores)]
            img_components[labels == label] = cor
            
            # Desenhar bounding box
            cv2.rectangle(img_boxes, (x, y), (x+w, y+h), cor, 3)
            cv2.putText(img_boxes, f"P{label}", (x, y-10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, cor, 2)
            
            print(f"      ‚úÖ Produto {label}: {area} pixels, bbox {w}x{h}, ratio {aspect_ratio:.2f}")
    
    # Salvar visualiza√ß√µes
    cv2.imwrite(os.path.join(pasta_resultado, "03_components_colored.jpg"), img_components)
    cv2.imwrite(os.path.join(pasta_resultado, "04_bounding_boxes.jpg"), img_boxes)
    
    # ===== PASSO 5: CLASSIFICA√á√ÉO POR FORMA =====
    print("   5Ô∏è‚É£ Classificando produtos por forma...")
    
    garrafas = []
    latas = []
    outros = []
    
    for produto in produtos:
        ratio = produto['aspect_ratio']
        area = produto['area']
        
        if ratio < 0.7:  # Mais alto que largo = garrafa
            tipo = "GARRAFA"
            garrafas.append(produto)
        elif 0.7 <= ratio <= 1.5:  # Propor√ß√£o equilibrada = lata
            tipo = "LATA"
            latas.append(produto)
        else:  # Muito largo = outro
            tipo = "OUTRO"
            outros.append(produto)
        
        produto['tipo'] = tipo
        print(f"      üìã Produto {produto['id']}: {tipo} (ratio {ratio:.2f})")
    
    return produtos, len(garrafas), len(latas)

def metodo_otsu_adaptativo(img, pasta_resultado):
    """Varia√ß√£o com Otsu autom√°tico"""
    print("\nüî¨ VARIA√á√ÉO: OTSU ADAPTATIVO")
    
    # Converter para escala de cinza
    if len(img.shape) == 3:
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    else:
        gray = img.copy()
    
    # Aplicar filtro Gaussiano para suavizar
    gray_blur = cv2.GaussianBlur(gray, (5, 5), 0)
    
    # Otsu autom√°tico
    thresh_otsu, binary_otsu = cv2.threshold(gray_blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
    print(f"   üìä Threshold Otsu autom√°tico: {thresh_otsu:.0f}")
    
    # Limpeza morfol√≥gica
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7))
    binary_clean = cv2.morphologyEx(binary_otsu, cv2.MORPH_OPEN, kernel)
    binary_clean = cv2.morphologyEx(binary_clean, cv2.MORPH_CLOSE, kernel)
    
    # Connected components
    num_labels, labels = cv2.connectedComponents(binary_clean)
    total_produtos = num_labels - 1
    
    # Salvar
    cv2.imwrite(os.path.join(pasta_resultado, "otsu_binary.jpg"), binary_clean)
    
    print(f"   ‚úì Otsu detectou: {total_produtos} produtos")
    return total_produtos

def main():
    """Teste do m√©todo Connected Components"""
    print("=" * 80)
    print("üî¨ M√âTODO CL√ÅSSICO: CONNECTED COMPONENTS LABELING")
    print("üìñ Baseado na pesquisa: varredura + agrupamento de pixels conectados")
    print("üéØ Ideal para: fundo removido ou uniforme")
    print("=" * 80)
    
    # Procurar por imagem Corona nos testes anteriores
    possible_paths = [
        "imagens_teste/corona_produtos.jpeg",
        "corona_produtos.jpeg",
        "produtos_corona.jpg",
        "anotada_104_1.jpeg.jpg",  # Uma das imagens que encontramos
        "anotada_105_2.jpeg.jpg"
    ]
    
    imagem_path = None
    for path in possible_paths:
        if os.path.exists(path):
            imagem_path = path
            print(f"‚úÖ Encontrada imagem: {path}")
            break
    
    if imagem_path is None:
        print("‚ùå N√£o foi poss√≠vel localizar imagem de teste")
        print("üìã Imagens dispon√≠veis:")
        for f in os.listdir('.'):
            if f.lower().endswith(('.jpg', '.jpeg', '.png')):
                print(f"   - {f}")
        return
    
    # Criar pasta de resultado
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    pasta_resultado = f"connected_components_{timestamp}"
    os.makedirs(pasta_resultado, exist_ok=True)
    
    print(f"üìÅ Pasta de resultado: {os.path.abspath(pasta_resultado)}")
    
    # Carregar imagem
    img = cv2.imread(imagem_path)
    if img is None:
        print(f"‚ùå Erro ao carregar: {imagem_path}")
        return
    
    altura, largura = img.shape[:2]
    print(f"üìè Imagem: {largura}x{altura}")
    
    # Aplicar m√©todo Connected Components
    produtos, num_garrafas, num_latas = metodo_connected_components(img, pasta_resultado)
    
    # Aplicar m√©todo Otsu como compara√ß√£o
    produtos_otsu = metodo_otsu_adaptativo(img, pasta_resultado)
    
    # ===== RESULTADO FINAL =====
    print(f"\n" + "="*50)
    print("üéâ RESULTADO CONNECTED COMPONENTS")
    print(f"="*50)
    print(f"üéØ Meta: 4 produtos Corona (3 garrafas + 1 lata)")
    print(f"‚úÖ Detectado: {len(produtos)} produtos total")
    print(f"   üç∫ Garrafas: {num_garrafas}")
    print(f"   ü•§ Latas: {num_latas}")
    print(f"üìä Compara√ß√£o Otsu: {produtos_otsu} produtos")
    
    # Avaliar resultado
    if len(produtos) == 4 and num_garrafas == 3 and num_latas == 1:
        print("üèÜ PERFEITO! Detectou exatamente 3 garrafas + 1 lata!")
        status = "PERFEITO"
    elif len(produtos) == 4:
        print(f"üéØ 4 produtos detectados, mas propor√ß√£o: {num_garrafas}G + {num_latas}L")
        status = "BOM"
    else:
        print(f"üîß Precisa ajustar: esperado 4, detectado {len(produtos)}")
        status = "AJUSTAR"
    
    # Relat√≥rio final
    with open(os.path.join(pasta_resultado, "relatorio_connected_components.txt"), 'w', encoding='utf-8') as f:
        f.write("M√âTODO CONNECTED COMPONENTS\n")
        f.write("=" * 30 + "\n\n")
        f.write("BASEADO NA PESQUISA:\n")
        f.write("1. Remo√ß√£o do fundo (limiariza√ß√£o)\n")
        f.write("2. Connected Component Labeling\n")
        f.write("3. An√°lise de cada componente\n")
        f.write("4. Classifica√ß√£o por forma\n\n")
        
        f.write(f"RESULTADO:\n")
        f.write(f"- Total detectado: {len(produtos)} produtos\n")
        f.write(f"- Garrafas: {num_garrafas}\n")
        f.write(f"- Latas: {num_latas}\n")
        f.write(f"- Status: {status}\n\n")
        
        f.write("DETALHES DOS PRODUTOS:\n")
        for produto in produtos:
            f.write(f"Produto {produto['id']} ({produto['tipo']}):\n")
            f.write(f"  - √Årea: {produto['area']} pixels\n")
            f.write(f"  - Propor√ß√£o: {produto['aspect_ratio']:.2f}\n")
            f.write(f"  - Bounding box: {produto['bbox']}\n\n")
    
    print(f"\nüìÑ Relat√≥rio: relatorio_connected_components.txt")
    print(f"üñºÔ∏è  Imagens geradas:")
    print(f"   - 01_grayscale.jpg (escala de cinza)")
    print(f"   - 02_binary_mask.jpg (m√°scara bin√°ria)")
    print(f"   - 03_components_colored.jpg (componentes coloridos)")
    print(f"   - 04_bounding_boxes.jpg (caixas delimitadoras)")
    
    try:
        os.startfile(os.path.abspath(pasta_resultado))
        print("üìÇ Pasta aberta!")
    except:
        pass

if __name__ == "__main__":
    main()